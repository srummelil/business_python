{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Background:***\n",
    "\n",
    "Steve Rummel, Senior Manager, Data Analytics & Digitization, created the below Python training course as part of his personal study of Python and development of training materials for business users of Python, on his own time and using his own resources prior to his employment at CVS. He granted permission to the the CVS Health Internal Audit department to adapt the case study into a more robustly documented course to help employees upskill in Python. Additional information in the commented sections has also been added by Alan Harrington, Data Scientist, for clarification and organizational purposes.\n",
    "\n",
    "***Scenario:***\n",
    "\n",
    "Your supervisor asks you to perform the following based on data they have collected as part of an audit:\n",
    "1) Clean and consistently format the data;\\\n",
    "2) Combine the data together;\\\n",
    "3) Identify all unique customers and customer IDs;\\\n",
    "4) Summarize the data to show how many people are in each client;\\\n",
    "5) Identify records with a service expiration date prior to system date;\\\n",
    "6) Show the top 5 records with customer expense greater than the client threshold;\\\n",
    "7) Summarize the data by client name and amount where customer expenses exceed the client threshold; and\\\n",
    "8) Graph the data by distribution of Count of Customers by Birth Year (Youâ€™ll need to use matplotlib).\n",
    "\n",
    "***Notes:***\n",
    "\n",
    "Note 1: The Python script below creates fake member data using the Faker library. Any semblance to real life individuals is purely coincidental.\n",
    "\n",
    "Note 2: Some functions were taken and adapted from various websites, including caktusgroup.com and stackoverflow.com. Any instances where functions were created that were not authored by Steve Rummel have been cited appropriately.\n",
    "\n",
    "Note 3: If a user is an Aetna user, reference the Aetna Nexus respository to ensure that the Python Libraries used herein are still able to be used.  \n",
    "\n",
    "Note 4: Any recommendations/feedback should be sent to Steve Rummel, steven.rummel@cvshealth.com, ***and*** Alan Harrington, harringtona@aetna.com. \n",
    "\n",
    "Note 5: Faker specific documentation can be found at https://faker.readthedocs.io/en/master/ for additional options to customize the script below\n",
    "\n",
    "Note 6: Pandas specific documentation can be found at https://pandas.pydata.org/.\n",
    "\n",
    "Note 7: NumPy specific documentation can be found at https://numpy.org/.\n",
    "\n",
    "Note 8: DateTime specific documentation can be found at https://docs.python.org/3/library/datetime.html.\n",
    "\n",
    "Note 9: Pathlib specific documentation can be found at https://docs.python.org/3/library/pathlib.html.\n",
    "\n",
    "Note 10: Matplotlib specific documentation can be found at https://matplotlib.org/stable/tutorials/introductory/pyplot.html.\n",
    "\n",
    "Note 11: String specific documentation can be found at https://docs.python.org/3/library/string.html\n",
    "\n",
    "Note 12: CSV specific documentation can be found at https://docs.python.org/3/library/csv.html\n",
    "\n",
    "Note 13: Random specific documentation can be found at https://docs.python.org/3/library/random.html\n",
    "\n",
    "Note 14: Users should familiarize themselves with the library documentation above.\n",
    "\n",
    "Note 15: In the 'Output' folder, there should be 9 files output:\n",
    "1. CLIENTS_MASTER.csv\n",
    "2. Data_MASTER.csv\n",
    "3. Data_MASTER.pkl\n",
    "4. File_1.csv\n",
    "5. File_2.csv\n",
    "6. File_3.csv\n",
    "7. File_4.csv\n",
    "8. File_5.csv\n",
    "9. SOLUTION_DATASET.csv\n",
    "\n",
    "Note 16: Rerunning the script will just overwrite the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries and modules.\n",
    "# Note, some users may not have some of these pre-installed.\n",
    "# Verify with the nexus to ensure correct version installation of libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "from datetime import timedelta as td\n",
    "from pathlib import Path\n",
    "from faker import Faker\n",
    "from faker.providers.person import Provider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Start date: 1923-08-01 00:00:00 End date: 2023-07-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#==========Establishing random seed, directory pathing, start date, end date, and size.==========\n",
    "\n",
    "# The user will need to use numpy to specify a specific random seed number to generate their results.\n",
    "# This will allow results to be reproducible and still random no matter the run.\n",
    "\n",
    "# The below uses NumPy to generate the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a destination directory 'dest_dir' for the files to be output to.\n",
    "# Recall, only 'Path' was imported from 'pathlib' as such, we initiate the input of the 'dest_dir' by \n",
    "# using Path.cwd() to return a new path object representing the current working directory (cwd for short).\n",
    "# '.joinpath()' is equivalent to combining the path with each of the other arguments in turn and, as such,\n",
    "# the output files will be sent only to the folder named 'Output'.\n",
    "# Note, this destination directory variable will be used in the following lines of code so if this variable name\n",
    "# is changed, the user MUST update the subsequent code!\n",
    "dest_dir = Path.cwd().joinpath('Output')\n",
    "\n",
    "# mkdir creates a new directory at a given path, in this case, the dest_directory path\n",
    "# parents = True means that any missing parents of this path are created as needed. So if an output folder\n",
    "# was not present, an Output folder would be created.\n",
    "# exist_ok means that the error code FileExistsError, will be ignored only if the last path component is not \n",
    "# an existing non-directory file\n",
    "Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create the 'end_date' variable and store within it the current date using pd.to_datetime('today').\n",
    "# This returns the current date at midnight, irrespective of when the script is run.\n",
    "# Note, you have to use .normalize() after to return the time portion as 00:00:00\n",
    "# E.g., if this is run on July 5, 2023 at 1:46PM, the 'end_date' would appear as \n",
    "# Timestamp('2023-07-05 13:46:16.133163'). However, if adding .normalize() to the end\n",
    "# it instead returns Timestamp('2023-07-05 00:00:00').\n",
    "# Thus the dataset's end date will be relative to the date the script is run.\n",
    "end_date = pd.to_datetime('today').normalize()\n",
    "\n",
    "# Create a start date based on our oldest customer being 100 years old\n",
    "# relative to the end_date specified above.\n",
    "start_date = end_date - datetime.timedelta(days=100 * 365)\n",
    "\n",
    "# Set a size for our resulting dataset in records.\n",
    "# Note: For training purposes, this should be set to a 100,000-500,000 range.\n",
    "size = 100000\n",
    "\n",
    "#==========Create the correct localizations using Faker.==========\n",
    "\n",
    "# Faker has multiple localizations - places one can get names for. Mexico, the US, etc.\n",
    "# We will use several locationlizations to obtain an diverse set of names, including those with\n",
    "# non-standard/unicode characters. The user will need to understand how to deal with these variations.\n",
    "\n",
    "# Loading the localizations specified into the localizations variable \n",
    "localizations = ['it_IT', 'en_US', 'es_ES', 'es_MX', 'fi_FI', 'nl_NL', 'en_IN', 'fr_FR']\n",
    "\n",
    "# Use 'Faker()' to initialize the generation of names with the above localizations\n",
    "fake = Faker(localizations)\n",
    "\n",
    "# To obtain only US addresses for our members, we create a new Faker generation instance and load it into a variable.\n",
    "# If you use 'fake' instead of 'addr' as a variable, all the names will appear as what the Faker library\n",
    "# creators consider \"normal\" American names, which mostly rely on popular American names from the mid-20th century.\n",
    "addr = Faker('en_US')\n",
    "\n",
    "#==========Create a tuple containing client_names.==========\n",
    "\n",
    "# We will create 6 client names, one of which is a TEST_CLIENT. The 'TEST_CLIENT' has been purposefully input\n",
    "# into the list of clients below to prepare users for looking for abnormal values in their data.\n",
    "# Note, the client_names variable is a tuple.\n",
    "\n",
    "client_names = (\"Acme Health Care\",\n",
    "                \"Massive Dynamic Employee HC\",\n",
    "                \"Federal Hornswogglers Union HC\",\n",
    "                \"Statler & Waldorf Investment Group\",\n",
    "                \"Amazing Distribution Co. Employee HC\",\n",
    "                \"TEST_CLIENT\"\n",
    "                )\n",
    "\n",
    "# The below will create a few functions. Functions are created by\n",
    "# using 'def' followed by the name of the function then (), with any parameters noted within the ().\n",
    "\n",
    "\n",
    "def random_dates(year, size):\n",
    "    '''The purpose of this function is to create random dates within a range between the start and end dates.\n",
    "    Adapted from: https://stackoverflow.com/a/50668285.'''\n",
    "    #Note, Unix timestamp is in nanoseconds by default, so divide it by\n",
    "    # 24*60*60*10**9 to convert to days.\n",
    "    # format=specifies the format in which the date will be parsed out as\n",
    "    # errors= inin this case, by default it raises an exception\n",
    "    start_u=pd.to_datetime('{}0101'.format(year), format=\"%Y%m%d\", errors='raise')\n",
    "    end_u=pd.to_datetime('{}1231'.format(year), format=\"%Y%m%d\", errors='raise')\n",
    "    divide_by = (24 * 60 * 60 * 10**9)\n",
    "    # Convert the start and end times accordingly\n",
    "    start_u = start_u.value // divide_by\n",
    "    end_u = end_u.value // divide_by\n",
    "    # Return a datetime that has a random integer based on the predefined start_u, end_u, and \n",
    "    # size paramters with a unit \"D\" for days.\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, size), unit=\"D\")\n",
    "\n",
    "\n",
    "def get_random_birthdates(start, end, size=10, mean=50, sd=10):\n",
    "    '''The purpose of this function is to create birthdates based on our above coded relative start and end dates.\n",
    "    The function assumes a normally distributed range of ages from 0 to 100 years old with a mean\n",
    "    of 50 and a standard deviation (sd) of 10, which gets us close to a noraml distrubtion of 100 years'''\n",
    "    num_people=10000\n",
    "    end_date = end #end = pd.to_datetime('today').normalize()\n",
    "    start_date = start #start = (end_date - datetime.timedelta(days=time_interval * 365))\n",
    "    # Returns the interval in both days and years \n",
    "    interval_in_days=(end_date - start_date).days   \n",
    "    interval_in_years=(end_date.year - start_date.year)   \n",
    "\n",
    "    # Create the variable 'df' and load into it a dataframe using the using integer variables \n",
    "    # rounded as whole numbers to pull random samples from a normal (Gaussian) distribution.\n",
    "    df = pd.DataFrame(np.random.normal(mean, sd, size).round(0).astype(int))\n",
    "    # Create a count of the dataframe as a grouped summary \n",
    "    summary = df[0].groupby(df[0]).count()\n",
    "\n",
    "    # Create an empty list named 'new_birthday_list'\n",
    "    new_birthday_list=[]\n",
    "    # Create a loop that for every year within the range (noted as 0 years to the \n",
    "    # interval_in_years as calculated above ) \n",
    "    for year in range(0, interval_in_years):\n",
    "        # Set the current year in the loop as the start_date year plus the year so \n",
    "        # it'll loop through every year.\n",
    "        current_year=start_date.year + year\n",
    "        # Try and except within a loop will try the below code first and if \n",
    "        # it does not work then the except code will be executed. \n",
    "        try:\n",
    "            # load the count of records for the year into a variable named 'count'\n",
    "            count=summary[year]\n",
    "            # use the random_dates function above and input the current_year and count as parameter values\n",
    "            # and store all values into a variable named 'test_dates'\n",
    "            test_dates=random_dates(current_year, count)\n",
    "            # Create another loop where for each date within the tests_dates\n",
    "            for date in test_dates:\n",
    "                # append each date to the new_birthday_list variable above\n",
    "                new_birthday_list.append(date)\n",
    "        except KeyError:\n",
    "            # in the instance where the try part of the loop cannot be executed, in the instance\n",
    "            # of a KeyError, put the count to 0\n",
    "            count=0\n",
    "    #Return the new_birthday_list as the output of the function\n",
    "    return new_birthday_list\n",
    "\n",
    "\n",
    "def generate_random_values(size, probabilities, categories):\n",
    "    \"\"\"Generate size-length ndarray of categories based on probabilities.\"\"\"\n",
    "    return np.random.choice(categories, size=size, p=probabilities)\n",
    "\n",
    "def assign_gender_based_name(gender):\n",
    "    '''The purpose of this function checks the gender value and returns a specific name value in accordance\n",
    "    with the Faker library results.'''\n",
    "    # Note, this means that it will still generate names for O and Empty values in the data\n",
    "    if gender=='M':\n",
    "        retval=fake.name_male()\n",
    "    elif gender=='F':\n",
    "        retval=fake.name_female()\n",
    "    else:\n",
    "        retval=fake.name()\n",
    "    return retval\n",
    "\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    '''The purpose of this function is to create a string ID for each member record.\n",
    "    Source of the function:\n",
    "    From: https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits/2257449'''\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "def descending_probabilities(value):\n",
    "    \"\"\"The purpose of this function is to generate a set of probabilities.\n",
    "    If we do not have a specific set of probabilities in mind for whatever\n",
    "    fake set of data elements we are populating, we can simply use this to\n",
    "    get a set of probabilities that will be allocated to the elements in\n",
    "    descending order of the proportion of the total number of elements\n",
    "    in a 'sum of the digits' manner.\"\"\"\n",
    "    inc = 0\n",
    "    values =[]\n",
    "    agg_prob=0\n",
    "    for i in range(value, 0, -1):\n",
    "        inc += i\n",
    "    for j in range(value, 1, -1):\n",
    "        prob=round(j/inc, 2)\n",
    "        values.append(prob)\n",
    "        agg_prob=agg_prob + prob\n",
    "    values.append(round(1-agg_prob, 2))\n",
    "    return values\n",
    "\n",
    "\n",
    "print(\"Done. Start date: {} End date: {}\".format(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! minimum birthdate: 1930-07-16 00:00:00 maximum birthdate: 2016-11-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#==========Create a plans table with maximum deductible and plan ID.==========\n",
    "\n",
    "# Create a blank dataframe and load the dataframe into the 'clients' variable\n",
    "clients=pd.DataFrame()\n",
    "# Create a column named 'CLIENT_NAME' and populate with the 6 client_names\n",
    "clients['CLIENT_NAME']=client_names\n",
    "\n",
    "# Create a column named 'CLIENT_ID' and populate with the value 6. \n",
    "# This will populate all values in each row with 6\n",
    "clients['CLIENT_ID'] = 6\n",
    "\n",
    "# Apply the 'id_generator' function on the CLIENT_ID field to overwrite the 6 values and\n",
    "# replace with a new ID\n",
    "clients['CLIENT_ID'] = clients['CLIENT_ID'].apply(id_generator)\n",
    "\n",
    "# Create a variable named 'client_bal_dist' and populate with a random \n",
    "# number based on a normal (Gaussian) distribution with a scale/standard deviation (spread or \"width\")\n",
    "# of 100 and a mean (\"centre\") of distribution/loc of 1,500, and a size equal to the index of the clients \n",
    "# variable and round the number to two.\n",
    "# This SHOULD return a NumPy array of 6 numbers  \n",
    "client_bal_dist=np.random.normal(size = len(clients.index), scale = 100, loc = 1500).round(2)\n",
    "\n",
    "# Use the values from the 'client_bal_dist' variable as values in a new column named 'THRESHOLD'\n",
    "# for the 'clients' dataframe. \n",
    "clients['THRESHOLD']=client_bal_dist\n",
    "\n",
    "# Export the clients data to a file named 'CLIENTS_MASTER.csv'\n",
    "clients.to_csv(dest_dir.joinpath('CLIENTS_MASTER.csv'), index=False)\n",
    "\n",
    "#==========Create customer data using our plan data.==========\n",
    "\n",
    "# Next, create our customers data using our plan data.\n",
    "\n",
    "# Create a blank dataframe.\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Assign a random plan identifier.\n",
    "\n",
    "# Load only the unique values from the CLIENT_ID column of clients into a variable named 'client_ids' \n",
    "client_ids=clients['CLIENT_ID'].unique()\n",
    "\n",
    "# Use the descending_probabilities function to generate a list of probabilities that are the same length \n",
    "# as the client_ids variable\n",
    "plan_probabilities=descending_probabilities(len(client_ids))\n",
    "\n",
    "# Create a column named 'Client_ID' in the 'df' dataframe and generate records\n",
    "# using the size as previously specified above, 100,000, set the probabilities\n",
    "# to plan_proabilities as defined above, and set the categories to client_ids.\n",
    "df['Client_ID'] = generate_random_values(size, probabilities=plan_probabilities, categories=client_ids)\n",
    "\n",
    "# Set a specific probability for each of the plans to appear wtihin the data\n",
    "p = (0.30, 0.30, 0.10, 0.05, 0.24, 0.01)\n",
    "plans = (\"A\", \"B\", \"C\", \"D\", \"F\", \"TEST\")\n",
    "# Use the generate_random_values function to generate values for a new field within\n",
    "# the 'df' dataframe named 'Plan_ID'.\n",
    "df['Plan_ID'] = generate_random_values(size, probabilities=p, categories=plans)\n",
    "\n",
    "# Create a field named 'Customer_ID' in the 'df' dataframe and populate with the value 9. \n",
    "# There is likely a better way to do this, but we need a random and\n",
    "# unique 'user id' so create one that is 9 alpha-numerals long.\n",
    "df['Customer_ID'] = 9\n",
    "\n",
    "# Apply the 'id_generator' function on the Customer_ID field to overwrite the 9 values and\n",
    "# replace with a new ID\n",
    "df['Customer_ID'] = df['Customer_ID'].apply(id_generator)\n",
    "\n",
    "# Create a field named 'ACCOUNT_STATUS' for the 'df' dataframe and \n",
    "# populate the field using the generate_random_values function\n",
    "# with the size equal to 100,000, as described above, probabilities set to \n",
    "# 94% and 6%, with categories of 'ACTIVE' and 'INACTIVE', respectively.\n",
    "df['ACCOUNT_STATUS'] = generate_random_values(size, probabilities=(.94, .06), categories=('ACTIVE', 'INACTIVE'))\n",
    "\n",
    "# Create a field named 'Gender' for the 'df' dataframe and \n",
    "# populate the field using the generate_random_values function\n",
    "# with the size equal to 100,000, as described above, probabilities set to \n",
    "# 49%, 49%, 1%, and 1%, with categories of \"M\", \"F\", \"O\", and \"\", respectively.\n",
    "# The \"\" represents a blank.\n",
    "# Trying to be inclusive, so added Other and blanks. \n",
    "df['Gender'] = generate_random_values(size, probabilities=(0.49, 0.49, 0.01, 0.01), categories=(\"M\", \"F\", \"O\", \"\"))\n",
    "\n",
    "# Create a field named 'Full_Name' for the 'df' dataframe to create\n",
    "# names strictly based on the Faker modules population of names. \n",
    "df['Full_Name'] = df['Gender'].apply(assign_gender_based_name)\n",
    "\n",
    "# Create a variable called 'addresses' and populate with an empty list, [].\n",
    "addresses=[]\n",
    "# Note, we have limited the addresses to only English characters for names, \n",
    "# but this can be changed if desired. \n",
    "for _ in range(size):\n",
    "    addresses.append(addr.address())\n",
    "\n",
    "# Also, using list comprehension we have replaced instances \n",
    "# where the address would move to a new line with ', ' and stored \n",
    "# the addresses into a new field within the 'df' dataframe.\n",
    "df['Address'] = [w.replace('\\n', ', ') for w in addresses]\n",
    "\n",
    "# Create the 'Birthdate' column in the 'df' dataframe using the get_random_birthdates\n",
    "# function using the start, end, and size parameters specified previously and with\n",
    "# a mean of 50 and standard deviation of 10.\n",
    "df['Birthdate'] = get_random_birthdates(start=start_date, end=end_date, size=size, mean=50, sd=10)\n",
    "# Create several birthdate fields of different formats to force students convert\n",
    "# each birthdate field to the same date format.\n",
    "df['Birthdate_01'] = df['Birthdate'].dt.strftime('%m/%d/%Y')\n",
    "df['Birthdate_02'] = df['Birthdate'].dt.strftime('%m%d%y')\n",
    "df['Birthdate_03'] = df['Birthdate'].dt.strftime('%m-%d-%Y')\n",
    "df['Birthdate_04'] = df['Birthdate'].dt.strftime('%Y%m%d')\n",
    "\n",
    "# Assign to the variable 'cust_bal_dist' variable random samples from a normal \n",
    "# (Gaussian) distribution, with a size equal to the index of the 'df' dataframe,\n",
    "# a scale/standard deviation (spread or \"width\") of 200, and a mean (\"center\") \n",
    "# of distribution/loc of 1,200, rounded to two decimal places.\n",
    "cust_bal_dist=np.random.normal(size = len(df.index), scale = 200, loc = 1200).round(2)\n",
    "\n",
    "# Create the field 'CUST_EXP' for the 'df' dataframe and populate it with values from\n",
    "# the cust_bal_dist variable.\n",
    "df['CUST_EXP']=cust_bal_dist\n",
    "\n",
    "# Create a field named 'SYSTEM_DATE' in the 'df' dataframe and populate it with\n",
    "# values datetime values using the end_date variable.\n",
    "# This will provide a Baseline date against which we generate everything else, \n",
    "# so we have relative ranges, errors, etc.\n",
    "df['SYSTEM_DATE']=pd.to_datetime(end_date)\n",
    "\n",
    "# Assign to the variable 'dist' variable random samples from a normal \n",
    "# (Gaussian) distribution, with a size equal to the index of the 'df' dataframe,\n",
    "# a scale/standard deviation (spread or \"width\") of 100, and the arithmetic \n",
    "# mean (\"center\") of distribution/loc of 190, rounding the values and ensuring the\n",
    "# values are an integer.\n",
    "\n",
    "dist=np.random.normal(size = size, scale = 100, loc = 190)\n",
    "dist=dist.round().astype(int)\n",
    "\n",
    "# Create a field named 'Service_Expiration_Date' in the 'df' dataframe.\n",
    "# We will add values to the original 'SYSTEM_DATE' field to ensure that,\n",
    "# for educational purposes, ~3-5% of our population are failures, which\n",
    "# represent instances where the Service_Expiration_Date occurred before\n",
    "# the SYSTEM_DATE. The Service_Expiration_Date field is populated by taking\n",
    "# the original SYSTEM_DATE value and adding to it the timedelta based\n",
    "# on the 'dist' variable calculated above in days.\n",
    "df['Service_Expiration_Date'] = df['SYSTEM_DATE'] + pd.to_timedelta(dist, unit='days')\n",
    "\n",
    "#export the 'df' data to both a pickle file and a csv file\n",
    "df.to_pickle(dest_dir.joinpath('Data_MASTER.pkl'))\n",
    "df.to_csv(dest_dir.joinpath('Data_MASTER.csv'))\n",
    "\n",
    "#print the minimum and maximium birthdates\n",
    "print(\"Done! minimum birthdate: {} maximum birthdate: {}\".format(min(df['Birthdate']), max(df['Birthdate'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving File_1.csv...\n",
      "Saving File_2.csv...\n",
      "Saving File_3.csv...\n",
      "Saving File_4.csv...\n",
      "Saving File_5.csv...\n",
      "Should have exported 100000 records.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Export into a set of files, using different birthday fields for each.\n",
    "\n",
    "# Create a list of the Birthdate columns previously created\n",
    "bdates = ['Birthdate', 'Birthdate_01', 'Birthdate_02', 'Birthdate_03', 'Birthdate_04']\n",
    "\n",
    "# Obtain the length of the list of bdates list into the 'iter_inc' variable\n",
    "iter_inc=len(bdates)\n",
    "\n",
    "# Obtain the length of the 'df' dataframe and load into the 'df_len' variable\n",
    "df_len = len(df.index)\n",
    "\n",
    "# Create an empty listing that and load into the 'result' variable\n",
    "result = []\n",
    "\n",
    "# Create a list of fields to retain, which will drop all non-necessary fields\n",
    "master_retain_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP', \n",
    "                        'Gender', 'Full_Name', 'Address',\n",
    "                        'Birthdate', 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "\n",
    "# Create the variable 'numfiles' (number of files) and set the value to 5\n",
    "numfiles=5\n",
    "\n",
    "# Create the variable 'inc' and set the value to 0\n",
    "inc=0\n",
    "\n",
    "# Create the variable 'start' and set the value to 0\n",
    "start=0\n",
    "\n",
    "# For file rows in range(), range has 3 parameters, start, stop, and step.\n",
    "# In this instance, the start is at 0, the stop is df_len+1 (this is due\n",
    "# to the stop parameter stopping 1 before the number specified), and\n",
    "# the step (which is the rounded number of the length of the dataframe\n",
    "# divided by the number of files, thus splitting the records per file \n",
    "# evenly between each saved file).\n",
    "for filerows in range(0, df_len+1, round(df_len/numfiles)):\n",
    "    # The modulus below is allowing us to select a different birthday\n",
    "    # field for each output file and cycle through, so if there are\n",
    "    # ten output files, each of the five fields will be used in 2 \n",
    "    # or three of them forcing users to format them correctly.\n",
    "    bday_field=bdates[inc % iter_inc]\n",
    "    \n",
    "    # Retains only the fields specified. Note, this is different than the \n",
    "    # master_retain_fields due to needing to substitute a field named \n",
    "    # Birthdate for the bday_field variable that is dynamic enough to \n",
    "    # cycle through the birthdate field name list\n",
    "    retain_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP',\n",
    "                     'Gender', 'Full_Name', 'Address',\n",
    "                     bday_field, 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "    \n",
    "    # If the file rows are greater than start, start being 0 as noted above\n",
    "    # upon the first run. \n",
    "    if filerows > start:\n",
    "        \n",
    "        # load into a variable named 'fname' the name of the csv file, being \n",
    "        # dynamic as a f-string to allow it to input the number of the \n",
    "        # file, e.g., File_1.csv, File_2.csv, etc.\n",
    "        fname='File_{}.csv'.format(inc)\n",
    "        \n",
    "        #print the name of each file as it is being saved. This message\n",
    "        # will appear at the bottom of the cell.\n",
    "        print(\"Saving {}...\".format(fname))\n",
    "        \n",
    "        # For retained fields in the 'df' dataframe, use integer-location (iloc)\n",
    "        # to slice the array from the start, 0 in the case of file_1.csv, to\n",
    "        # the end of filerows, and export as a csv which will be output\n",
    "        # to the 'dest_dir' path, using the retain_fields 'header' variable\n",
    "        # keeping the index as False (which does not write row names), and\n",
    "        # set quoting to csv.QUOTE_ALL to quote everything regardless of field type.\n",
    "        df[retain_fields].iloc[start:filerows].to_csv(dest_dir.joinpath(fname),\n",
    "                                                      header=retain_fields,\n",
    "                                                      index=False,\n",
    "                                                      quoting=csv.QUOTE_ALL)\n",
    "    # Replace the original value of the start variable with the filerows integer\n",
    "    start=filerows\n",
    "    # Replace the value of 'inc' by adding 1 to the 'inc' variable every iteration\n",
    "    inc += 1\n",
    "   \n",
    "# Print a message to note the number of records that should have been exported.\n",
    "# This serves as a double check to the user to compare the code to the output.\n",
    "print(\"Should have exported {} records.\".format(df_len))\n",
    "\n",
    "# Print \"Done!\" as a final message to know when the code has finished running.\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting solution dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create a variable 'header_fields' variable with the correct final fields\n",
    "# to be used for the solution set.\n",
    "header_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP',\n",
    "                 'Gender', 'Full_Name', 'Address',\n",
    "                 'CUSTOMER_BIRTHDAY', 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "\n",
    "# Print the message, \"Exporting solution dataset...\"\n",
    "print(\"Exporting solution dataset...\")\n",
    "\n",
    "# Format the 'df' dataframe fields to only the 'header_fields' above and\n",
    "# export to a csv file named 'SOLUTION_DATASET.csv', not writing \n",
    "# row names (index=false) and quoting everything.\n",
    "df[master_retain_fields].to_csv(dest_dir.joinpath('SOLUTION_DATASET.csv'),\n",
    "                                header=header_fields,\n",
    "                                index=False,\n",
    "                                quoting=csv.QUOTE_ALL)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The below is the above code all formatted in one cell without the comments to serve as an example of the whole code being processed at once. Users can run this cell as needed. Note, whenever writing code some comments should be left to help with review of documentation, but not to the same degree as the above.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Start date: 1923-08-01 00:00:00 End date: 2023-07-07 00:00:00\n",
      "Done! minimum birthdate: 1930-07-16 00:00:00 maximum birthdate: 2016-11-24 00:00:00\n",
      "Saving File_1.csv...\n",
      "Saving File_2.csv...\n",
      "Saving File_3.csv...\n",
      "Saving File_4.csv...\n",
      "Saving File_5.csv...\n",
      "Should have exported 100000 records.\n",
      "Exporting solution dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "from datetime import timedelta as td\n",
    "from pathlib import Path\n",
    "from faker import Faker\n",
    "from faker.providers.person import Provider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "dest_dir = Path.cwd().joinpath('Output')\n",
    "Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "end_date = pd.to_datetime('today').normalize()\n",
    "start_date = end_date - datetime.timedelta(days=100 * 365)\n",
    "size = 100000\n",
    "localizations = ['it_IT', 'en_US', 'es_ES', 'es_MX', 'fi_FI', 'nl_NL', 'en_IN', 'fr_FR']\n",
    "fake = Faker(localizations)\n",
    "addr = Faker('en_US')\n",
    "client_names = (\"Acme Health Care\",\n",
    "                \"Massive Dynamic Employee HC\",\n",
    "                \"Federal Hornswogglers Union HC\",\n",
    "                \"Statler & Waldorf Investment Group\",\n",
    "                \"Amazing Distribution Co. Employee HC\",\n",
    "                \"TEST_CLIENT\"\n",
    "                )\n",
    "\n",
    "def random_dates(year, size):\n",
    "    start_u=pd.to_datetime('{}0101'.format(year), format=\"%Y%m%d\", errors='raise')\n",
    "    end_u=pd.to_datetime('{}1231'.format(year), format=\"%Y%m%d\", errors='raise')\n",
    "    divide_by = (24 * 60 * 60 * 10**9)\n",
    "    start_u = start_u.value // divide_by\n",
    "    end_u = end_u.value // divide_by\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, size), unit=\"D\")\n",
    "\n",
    "def get_random_birthdates(start, end, size=10, mean=50, sd=10):\n",
    "    num_people=10000\n",
    "    end_date = end \n",
    "    start_date = start \n",
    "    interval_in_days=(end_date - start_date).days   \n",
    "    interval_in_years=(end_date.year - start_date.year)   \n",
    "    df = pd.DataFrame(np.random.normal(mean, sd, size).round(0).astype(int))\n",
    "    summary = df[0].groupby(df[0]).count()\n",
    "    new_birthday_list=[]\n",
    "    for year in range(0, interval_in_years):\n",
    "        current_year=start_date.year + year\n",
    "        try:\n",
    "            count=summary[year]\n",
    "            test_dates=random_dates(current_year, count)\n",
    "            for date in test_dates:\n",
    "                new_birthday_list.append(date)\n",
    "        except KeyError:\n",
    "            count=0\n",
    "    return new_birthday_list\n",
    "\n",
    "def generate_random_values(size, probabilities, categories):\n",
    "    return np.random.choice(categories, size=size, p=probabilities)\n",
    "\n",
    "def assign_gender_based_name(gender):\n",
    "    if gender=='M':\n",
    "        retval=fake.name_male()\n",
    "    elif gender=='F':\n",
    "        retval=fake.name_female()\n",
    "    else:\n",
    "        retval=fake.name()\n",
    "    return retval\n",
    "\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "def descending_probabilities(value):\n",
    "    inc = 0\n",
    "    values =[]\n",
    "    agg_prob=0\n",
    "    for i in range(value, 0, -1):\n",
    "        inc += i\n",
    "    for j in range(value, 1, -1):\n",
    "        prob=round(j/inc, 2)\n",
    "        values.append(prob)\n",
    "        agg_prob=agg_prob + prob\n",
    "    values.append(round(1-agg_prob, 2))\n",
    "    return values\n",
    "\n",
    "print(\"Done. Start date: {} End date: {}\".format(start_date, end_date))\n",
    "\n",
    "clients=pd.DataFrame()\n",
    "clients['CLIENT_NAME']=client_names\n",
    "clients['CLIENT_ID'] = 6\n",
    "clients['CLIENT_ID'] = clients['CLIENT_ID'].apply(id_generator)\n",
    "client_bal_dist=np.random.normal(size = len(clients.index), scale = 100, loc = 1500).round(2)\n",
    "clients['THRESHOLD']=client_bal_dist\n",
    "clients.to_csv(dest_dir.joinpath('CLIENTS_MASTER.csv'), index=False)\n",
    "df = pd.DataFrame()\n",
    "client_ids=clients['CLIENT_ID'].unique()\n",
    "plan_probabilities=descending_probabilities(len(client_ids))\n",
    "df['Client_ID'] = generate_random_values(size, probabilities=plan_probabilities, categories=client_ids)\n",
    "p = (0.30, 0.30, 0.10, 0.05, 0.24, 0.01)\n",
    "plans = (\"A\", \"B\", \"C\", \"D\", \"F\", \"TEST\")\n",
    "df['Plan_ID'] = generate_random_values(size, probabilities=p, categories=plans)\n",
    "df['Customer_ID'] = 9\n",
    "df['Customer_ID'] = df['Customer_ID'].apply(id_generator)\n",
    "df['ACCOUNT_STATUS'] = generate_random_values(size, probabilities=(.94, .06), categories=('ACTIVE', 'INACTIVE'))\n",
    "df['Gender'] = generate_random_values(size, probabilities=(0.49, 0.49, 0.01, 0.01), categories=(\"M\", \"F\", \"O\", \"\"))\n",
    "df['Full_Name'] = df['Gender'].apply(assign_gender_based_name)\n",
    "addresses=[]\n",
    "\n",
    "for _ in range(size):\n",
    "    addresses.append(addr.address())\n",
    "\n",
    "df['Address'] = [w.replace('\\n', ', ') for w in addresses]\n",
    "df['Birthdate'] = get_random_birthdates(start=start_date, end=end_date, size=size, mean=50, sd=10)\n",
    "df['Birthdate_01'] = df['Birthdate'].dt.strftime('%m/%d/%Y')\n",
    "df['Birthdate_02'] = df['Birthdate'].dt.strftime('%m%d%y')\n",
    "df['Birthdate_03'] = df['Birthdate'].dt.strftime('%m-%d-%Y')\n",
    "df['Birthdate_04'] = df['Birthdate'].dt.strftime('%Y%m%d')\n",
    "cust_bal_dist=np.random.normal(size = len(df.index), scale = 200, loc = 1200).round(2)\n",
    "df['CUST_EXP']=cust_bal_dist\n",
    "df['SYSTEM_DATE']=pd.to_datetime(end_date)\n",
    "dist=np.random.normal(size = size, scale = 100, loc = 190)\n",
    "dist=dist.round().astype(int)\n",
    "df['Service_Expiration_Date'] = df['SYSTEM_DATE'] + pd.to_timedelta(dist, unit='days')\n",
    "df.to_pickle(dest_dir.joinpath('Data_MASTER.pkl'))\n",
    "df.to_csv(dest_dir.joinpath('Data_MASTER.csv'))\n",
    "print(\"Done! minimum birthdate: {} maximum birthdate: {}\".format(min(df['Birthdate']), max(df['Birthdate'])))\n",
    "bdates = ['Birthdate', 'Birthdate_01', 'Birthdate_02', 'Birthdate_03', 'Birthdate_04']\n",
    "iter_inc=len(bdates)\n",
    "df_len = len(df.index)\n",
    "result = []\n",
    "master_retain_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP', \n",
    "                        'Gender', 'Full_Name', 'Address',\n",
    "                        'Birthdate', 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "numfiles=5\n",
    "inc=0\n",
    "start=0\n",
    "\n",
    "for filerows in range(0, df_len+1, round(df_len/numfiles)):\n",
    "    bday_field=bdates[inc % iter_inc]\n",
    "    retain_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP',\n",
    "                     'Gender', 'Full_Name', 'Address',\n",
    "                     bday_field, 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "    if filerows > start:\n",
    "        fname='File_{}.csv'.format(inc)\n",
    "        print(\"Saving {}...\".format(fname))\n",
    "        df[retain_fields].iloc[start:filerows].to_csv(dest_dir.joinpath(fname),\n",
    "                                                      header=retain_fields,\n",
    "                                                      index=False,\n",
    "                                                      quoting=csv.QUOTE_ALL)\n",
    "    start=filerows\n",
    "    inc += 1\n",
    "\n",
    "print(\"Should have exported {} records.\".format(df_len))\n",
    "\n",
    "header_fields = ['Customer_ID', 'Client_ID', 'Plan_ID', 'CUST_EXP',\n",
    "                 'Gender', 'Full_Name', 'Address',\n",
    "                 'CUSTOMER_BIRTHDAY', 'Service_Expiration_Date', 'SYSTEM_DATE']\n",
    "print(\"Exporting solution dataset...\")\n",
    "df[master_retain_fields].to_csv(dest_dir.joinpath('SOLUTION_DATASET.csv'),\n",
    "                                header=header_fields,\n",
    "                                index=False,\n",
    "                                quoting=csv.QUOTE_ALL)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
